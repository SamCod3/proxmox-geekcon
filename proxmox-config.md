# ConfiguraciÃ³n Proxmox VE - geekcon

> **Ãšltima actualizaciÃ³n:** 26 Diciembre 2025  
> **IP:** 192.168.50.8  
> **Usuario:** root

---

# ðŸ–¥ï¸ NODO PROXMOX (Host)

Todo en esta secciÃ³n estÃ¡ configurado directamente en el nodo Proxmox.

---

## Sistema

| Componente | Valor |
|------------|-------|
| **Hostname** | geekcon |
| **Proxmox VE** | 9.1.0 |
| **Kernel** | 6.17.4-1-pve |
| **CPU** | AMD Ryzen AI 9 HX 370 w/ Radeon 890M |
| **Cores/Threads** | 12 cores / 24 threads |
| **RAM** | 30 GB |
| **GPU** | AMD Radeon 890M (integrada) |
| **NPU** | AMD XDNA (Ryzen AI) |

---

## ï¿½ Repositorios APT

### ConfiguraciÃ³n para uso sin suscripciÃ³n

Por defecto, Proxmox viene con el repositorio enterprise (de pago). Hay que deshabilitarlo y habilitar el repositorio gratuito.

```bash
# 1. Deshabilitar repositorio enterprise (renombrar)
mv /etc/apt/sources.list.d/pve-enterprise.sources /etc/apt/sources.list.d/pve-enterprise.sources.disabled

# 2. Crear repositorio no-subscription (gratuito)
cat > /etc/apt/sources.list.d/pve-no-subscription.sources << 'EOF'
Types: deb
URIs: http://download.proxmox.com/debian/pve
Suites: trixie
Components: pve-no-subscription
Signed-By: /usr/share/keyrings/proxmox-archive-keyring.gpg
EOF

# 3. Configurar Ceph sin suscripciÃ³n (opcional, si usas Ceph)
cat > /etc/apt/sources.list.d/ceph.sources << 'EOF'
Types: deb
URIs: http://download.proxmox.com/debian/ceph-squid
Suites: trixie
Components: no-subscription
Signed-By: /usr/share/keyrings/proxmox-archive-keyring.gpg
EOF

# 4. Actualizar
apt update && apt upgrade -y
```

### Estado actual de los repositorios

| Archivo | Estado | DescripciÃ³n |
|---------|--------|-------------|
| `pve-enterprise.sources.disabled` | âŒ Deshabilitado | Repo de pago |
| `pve-no-subscription.sources` | âœ… Habilitado | Repo gratuito Proxmox |
| `ceph.sources` | âœ… Habilitado | Ceph Squid (no-subscription) |
| `debian.sources` | âœ… Habilitado | Debian Trixie base |

---

## ï¿½ðŸ’¾ Almacenamiento

### Discos fÃ­sicos

| Disco | Tipo | TamaÃ±o | Uso |
|-------|------|--------|-----|
| **nvme1n1** | NVMe | 1.82 TB | Sistema + VMs (LVM) |
| **nvme0n1** | NVMe | 1.9 TB | Backups (`/mnt/backups`) |

### ðŸ“Š Esquema del disco del sistema (nvme1n1 - 1.82 TB)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DISCO FÃSICO: nvme1n1 (1.82 TB)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ nvme1n1p1â”‚  â”‚ nvme1n1p2â”‚  â”‚              nvme1n1p3                     â”‚ â”‚
â”‚  â”‚  1 MB    â”‚  â”‚  1 GB    â”‚  â”‚              1.82 TB                       â”‚ â”‚
â”‚  â”‚  (BIOS)  â”‚  â”‚ /boot/efiâ”‚  â”‚            LVM2_member                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                           â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VOLUME GROUP: pve (1.82 TB total)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  pve-root  â”‚  â”‚  pve-swap  â”‚  â”‚           pve-data (THIN POOL)         â”‚ â”‚
â”‚  â”‚   96 GB    â”‚  â”‚   8 GB     â”‚  â”‚              1.71 TB                   â”‚ â”‚
â”‚  â”‚   ext4     â”‚  â”‚   swap     â”‚  â”‚                                        â”‚ â”‚
â”‚  â”‚            â”‚  â”‚            â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  Usado:    â”‚  â”‚            â”‚  â”‚  â”‚       Espacio THIN POOL          â”‚  â”‚ â”‚
â”‚  â”‚   5 GB     â”‚  â”‚            â”‚  â”‚  â”‚                                  â”‚  â”‚ â”‚
â”‚  â”‚  (6%)      â”‚  â”‚            â”‚  â”‚  â”‚  Total:     1.71 TB              â”‚  â”‚ â”‚
â”‚  â”‚            â”‚  â”‚            â”‚  â”‚  â”‚  Usado:     21 GB (1.24%)        â”‚  â”‚ â”‚
â”‚  â”‚  Libre:    â”‚  â”‚            â”‚  â”‚  â”‚  Libre:    ~1.69 TB              â”‚  â”‚ â”‚
â”‚  â”‚   85 GB    â”‚  â”‚            â”‚  â”‚  â”‚                                  â”‚  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”‚
â”‚       â”‚               â”‚          â”‚  â”‚  â”‚   vm-100-disk-0            â”‚  â”‚  â”‚ â”‚
â”‚       â–¼               â–¼          â”‚  â”‚  â”‚   (docker-commander)       â”‚  â”‚  â”‚ â”‚
â”‚      /              [SWAP]       â”‚  â”‚  â”‚                            â”‚  â”‚  â”‚ â”‚
â”‚                                  â”‚  â”‚  â”‚   TamaÃ±o virtual: 32 GB    â”‚  â”‚  â”‚ â”‚
â”‚                                  â”‚  â”‚  â”‚   Usado real:    ~21 GB    â”‚  â”‚  â”‚ â”‚
â”‚                                  â”‚  â”‚  â”‚   (66% del virtual)        â”‚  â”‚  â”‚ â”‚
â”‚                                  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â”‚
â”‚                                  â”‚  â”‚                                  â”‚  â”‚ â”‚
â”‚                                  â”‚  â”‚  ðŸ†“ Espacio para nuevas VMs/LXC  â”‚  â”‚ â”‚
â”‚                                  â”‚  â”‚     ~1.69 TB disponibles         â”‚  â”‚ â”‚
â”‚                                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ ðŸ”¹ Espacio libre en VG (sin asignar): 16.24 GB                          â”‚â”‚
â”‚  â”‚    (Disponible para expandir pve-root, pve-swap o pve-data)             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ’¡ Thin Provisioning

| Concepto | ExplicaciÃ³n |
|----------|-------------|
| **Thin Pool** | Es un "depÃ³sito" de espacio del que se asigna dinÃ¡micamente |
| **TamaÃ±o virtual** | Lo que "ve" la VM/LXC (ej: 32 GB para docker-commander) |
| **Uso real** | Solo se consume espacio cuando se escriben datos realmente |

### ðŸ“ Almacenamiento en Proxmox

| Storage | Tipo | Contenido | TamaÃ±o |
|---------|------|-----------|--------|
| `local` | dir | ISOs, templates, snippets | 94 GB |
| `local-lvm` | lvmthin | Discos de VMs/LXC | 1.71 TB |
| `backup-storage` | dir | Backups, ISOs, templates | 1.9 TB |

---

### ðŸ’¿ Disco de Backups (nvme0n1 - 1.9 TB)

Este disco **NO se formatea** en una reinstalaciÃ³n. Contiene los backups y datos persistentes.

| Propiedad | Valor |
|-----------|-------|
| **Disco** | nvme0n1 |
| **TamaÃ±o** | 1.9 TB |
| **Formato** | ext4 |
| **Montaje** | `/mnt/backups` |
| **UUID actual** | `ddee81bf-1ac8-4ea3-b1e4-d28c2f74158d` |
| **Storage Proxmox** | `backup-storage` |

#### ConfiguraciÃ³n tras reinstalaciÃ³n

```bash
# 1. Crear punto de montaje
mkdir -p /mnt/backups

# 2. Obtener UUID del disco (puede haber cambiado el nombre del dispositivo)
# Buscar el disco de ~1.9TB con formato ext4
lsblk -o NAME,SIZE,FSTYPE,UUID
# O especÃ­ficamente:
blkid | grep ext4

# 3. AÃ±adir a fstab usando el UUID detectado
# Reemplazar XXXXXXXX con el UUID real del disco
UUID_BACKUP=$(blkid -s UUID -o value /dev/nvme0n1)
echo "UUID=$UUID_BACKUP /mnt/backups ext4 defaults 0 2" >> /etc/fstab

# 4. Montar
mount -a

# 5. Verificar
df -h /mnt/backups
ls -la /mnt/backups/
```

#### Registrar como storage en Proxmox

```bash
# AÃ±adir storage (si no existe)
pvesm add dir backup-storage --path /mnt/backups --content vztmpl,backup,snippets,iso

# Verificar
pvesm status
```

#### Contenido esperado

```
/mnt/backups/
â”œâ”€â”€ dump/        # Backups de VMs/LXC (vzdump)
â”œâ”€â”€ images/      # (vacÃ­o normalmente)
â”œâ”€â”€ snippets/    # Scripts y configs
â”œâ”€â”€ template/    # Templates de contenedores
â”‚   â”œâ”€â”€ cache/
â”‚   â””â”€â”€ iso/     # ISOs
â””â”€â”€ lost+found/
```

---

## ðŸŒ Red

**Archivo:** `/etc/network/interfaces`

```
vmbr0 (Bridge Principal)
â”œâ”€â”€ IP: 192.168.50.8/24
â”œâ”€â”€ Gateway: 192.168.50.1
â”œâ”€â”€ Puerto fÃ­sico: nic0
â””â”€â”€ Wake-on-LAN: Habilitado (ethtool -s nic0 wol g)
```

**Interfaces adicionales:** nic1, nic2 (manual, sin configurar)

---

## âš¡ Tuned - OptimizaciÃ³n CPU

**Paquete:** tuned  
**Perfil activo:** `proxmox-ryzen`

### InstalaciÃ³n

```bash
# 1. Instalar tuned
apt update && apt install tuned -y

# 2. Crear directorio del perfil
mkdir -p /etc/tuned/profiles/proxmox-ryzen

# 3. Crear archivo de configuraciÃ³n
cat > /etc/tuned/profiles/proxmox-ryzen/tuned.conf << 'EOF'
[main]
include=virtual-host

[cpu]
# CRÃTICO: Para amd_pstate_epp, 'powersave' habilita el modo dinÃ¡mico.
# Si se deja en 'performance', el EPP se bloquea y no cambia.
governor=powersave
energy_performance_preference=balance_performance
EOF

# 4. Activar el perfil
tuned-adm profile proxmox-ryzen

# 5. Verificar
tuned-adm active
```

| ParÃ¡metro | Valor | PropÃ³sito |
|-----------|-------|-----------|
| **include** | `virtual-host` | Hereda config optimizada para hipervisores |
| **governor** | `powersave` | Con `amd_pstate_epp`, permite escalado dinÃ¡mico |
| **energy_performance_preference** | `balance_performance` | Equilibrio rendimiento/eficiencia |

---

## ðŸŒ¡ï¸ MonitorizaciÃ³n TÃ©rmica

### InstalaciÃ³n

```bash
# 1. Instalar lm-sensors
apt install lm-sensors -y

# 2. Crear el script de vigilancia
cat > /usr/local/bin/temp-watchdog.sh << 'EOF'
#!/bin/bash
# CONFIGURACION
UMBRAL_WARN=85
UMBRAL_CRIT=95
SENSOR_CMD="sensors"

# Obtener temperatura actual de Tctl (Ryzen)
# Extrae solo el numero flotante
TEMP=$(sensors -u k10temp-pci-00c3 | grep "temp1_input" | awk '{print $2}')
TEMP_INT=${TEMP%.*}

# Logica de Alerta
if [ "$TEMP_INT" -ge "$UMBRAL_CRIT" ]; then
    msg="CRITICAL: CPU Temperature at ${TEMP}Â°C. Risk of thermal shutdown."
    echo "$msg" | logger -t temp-watchdog -p user.emerg
    # Descomentar si tienes email configurado en Proxmox
    # echo "$msg" | mail -s "PVE THERMAL CRITICAL" root
elif [ "$TEMP_INT" -ge "$UMBRAL_WARN" ]; then
    msg="WARNING: CPU Temperature high (${TEMP}Â°C)."
    echo "$msg" | logger -t temp-watchdog -p user.alert
fi
EOF

# 3. Hacer ejecutable
chmod +x /usr/local/bin/temp-watchdog.sh

# 4. Crear tarea cron (ejecutar cada minuto)
cat > /etc/cron.d/temp-watchdog << 'EOF'
* * * * * root /usr/local/bin/temp-watchdog.sh
EOF

# 5. Verificar que funciona
/usr/local/bin/temp-watchdog.sh
sensors | grep Tctl
```

### ConfiguraciÃ³n

| Umbral | Temperatura | AcciÃ³n |
|--------|-------------|--------|
| âš ï¸ **WARNING** | â‰¥ 85Â°C | Log a syslog (user.alert) |
| ðŸ”´ **CRITICAL** | â‰¥ 95Â°C | Log a syslog (user.emerg) |

**Ver alertas:** `journalctl -t temp-watchdog`

---

## ðŸ“Š Script sysinfo (estado del sistema)

Script para ver rÃ¡pidamente el estado del nodo con temperaturas, recursos y VMs.

### InstalaciÃ³n

```bash
cat > /usr/local/bin/sysinfo << 'EOF'
#!/bin/bash
GREEN='\033[32m'; YELLOW='\033[33m'; RED='\033[31m'; CYAN='\033[36m'; BOLD='\033[1m'; NC='\033[0m'

color_temp() {
  t=${1%.*}
  [[ $t -ge 80 ]] && echo -e "${RED}$1Â°C${NC}" && return
  [[ $t -ge 60 ]] && echo -e "${YELLOW}$1Â°C${NC}" && return
  echo -e "${GREEN}$1Â°C${NC}"
}

CPU=$(sensors k10temp-pci-00c3 2>/dev/null | awk '/Tctl/{gsub(/[+Â°C]/,"",$2);print $2}')
GPU=$(sensors amdgpu-pci-c700 2>/dev/null | awk '/edge/{gsub(/[+Â°C]/,"",$2);print $2}')
PWR=$(sensors amdgpu-pci-c700 2>/dev/null | awk '/PPT/{print $2}')
NV1=$(sensors nvme-pci-c100 2>/dev/null | awk '/Composite/{gsub(/[+Â°C]/,"",$2);print $2}')
NV2=$(sensors nvme-pci-c600 2>/dev/null | awk '/Composite/{gsub(/[+Â°C]/,"",$2);print $2}')
RAM1=$(sensors spd5118-i2c-2-50 2>/dev/null | awk '/temp1/{gsub(/[+Â°C]/,"",$2);print $2;exit}')
RAM2=$(sensors spd5118-i2c-2-51 2>/dev/null | awk '/temp1/{gsub(/[+Â°C]/,"",$2);print $2;exit}')
WIFI=$(sensors mt7925_phy0-pci-c300 2>/dev/null | awk '/temp1/{gsub(/[+Â°C]/,"",$2);print $2}')
CPU_PWR=$(turbostat --Summary --quiet --show PkgWatt sleep 1 2>&1 | tail -1)
RAM_U=$(free -h | awk '/Mem/{print $3}'); RAM_T=$(free -h | awk '/Mem/{print $2}')
DISK=$(df -h / | awk 'NR==2{print $5}')
VMS=$(qm list 2>/dev/null | grep -c running); LXC=$(pct list 2>/dev/null | grep -c running)
BIOS=$(dmidecode -s bios-version 2>/dev/null)
BIOS_DATE=$(dmidecode -s bios-release-date 2>/dev/null)
EC=$(cat /sys/class/dmi/id/ec_firmware_release 2>/dev/null || echo "N/A")

echo -e "${BOLD}${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${BOLD}${CYAN}  ðŸ–¥ï¸  PROXMOX: geekcon${NC}"
echo -e "${BOLD}${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${CYAN}  ðŸ”§  Firmware${NC}"
echo -e "      BIOS:           ${BIOS} (${BIOS_DATE})"
echo -e "      EC:             ${EC}"
echo -e "${CYAN}  ðŸŒ¡ï¸  Temperaturas${NC}"
echo -e "      CPU (Ryzen):    $(color_temp $CPU)"
echo -e "      GPU (890M):     $(color_temp $GPU) (${PWR}W)"
echo -e "      NVMe Sistema:   $(color_temp $NV1)"
echo -e "      NVMe Backups:   $(color_temp $NV2)"
echo -e "      RAM:            $(color_temp $RAM1) / $(color_temp $RAM2)"
echo -e "      WiFi:           $(color_temp $WIFI)"
echo -e "${CYAN}  âš¡  Consumo${NC}"
echo -e "      CPU:            ${CPU_PWR}W"
echo -e "      GPU:            ${PWR}W"
echo -e "${CYAN}  ðŸ“Š  Recursos${NC}"
echo -e "      RAM:            $RAM_U / $RAM_T"
echo -e "      Disco /:        $DISK"
echo -e "${CYAN}  ðŸ–¼ï¸  VirtualizaciÃ³n${NC}"
echo -e "      VMs:            $VMS corriendo"
echo -e "      LXC:            $LXC corriendo"
echo -e "${BOLD}${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
EOF

chmod +x /usr/local/bin/sysinfo
```

### Uso

```bash
sysinfo
```

---

## ï¿½ Wake-on-LAN

Permite encender el servidor remotamente desde la red.

### Estado actual

```
Supports Wake-on: pumbg
Wake-on: g (Magic Packet)
```

### InstalaciÃ³n

El WoL se configura en `/etc/network/interfaces` como post-up en la interfaz fÃ­sica:

```bash
# Ya incluido en la configuraciÃ³n de red:
auto nic0
iface nic0 inet manual
        post-up /usr/sbin/ethtool -s nic0 wol g
```

### Verificar

```bash
ethtool nic0 | grep Wake
# Debe mostrar: Wake-on: g
```

### Encender remotamente

Desde otro equipo en la red:

```bash
# Linux
wakeonlan BC:24:11:XX:XX:XX

# O con etherwake
etherwake -i eth0 BC:24:11:XX:XX:XX
```

> **Nota:** TambiÃ©n debe estar habilitado en la BIOS del mini PC.

---

## ðŸš« Quitar aviso de suscripciÃ³n (Subscription Nag)

Script que elimina el popup de suscripciÃ³n de la interfaz web y mÃ³vil de Proxmox.

### InstalaciÃ³n

```bash
# 1. Crear el script
cat > /usr/local/bin/pve-remove-nag.sh << 'EOF'
#!/bin/sh
WEB_JS=/usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js
if [ -s "$WEB_JS" ] && ! grep -q NoMoreNagging "$WEB_JS"; then
    echo "Patching Web UI nag..."
    sed -i -e "/data\.status/ s/!//" -e "/data\.status/ s/active/NoMoreNagging/" "$WEB_JS"
fi

MOBILE_TPL=/usr/share/pve-yew-mobile-gui/index.html.tpl
MARKER="<!-- MANAGED BLOCK FOR MOBILE NAG -->"
if [ -f "$MOBILE_TPL" ] && ! grep -q "$MARKER" "$MOBILE_TPL"; then
    echo "Patching Mobile UI nag..."
    printf "%s\n" \
      "$MARKER" \
      "<script>" \
      "  function removeSubscriptionElements() {" \
      "    const dialogs = document.querySelectorAll('dialog.pwt-outer-dialog');" \
      "    dialogs.forEach(dialog => {" \
      "      const text = (dialog.textContent || '').toLowerCase();" \
      "      if (text.includes('subscription')) {" \
      "        dialog.remove();" \
      "      }" \
      "    });" \
      "    const cards = document.querySelectorAll('.pwt-card.pwt-p-2.pwt-d-flex.pwt-interactive.pwt-justify-content-center');" \
      "    cards.forEach(card => {" \
      "      const text = (card.textContent || '').toLowerCase();" \
      "      const hasButton = card.querySelector('button');" \
      "      if (!hasButton && text.includes('subscription')) {" \
      "        card.remove();" \
      "      }" \
      "    });" \
      "  }" \
      "  const observer = new MutationObserver(removeSubscriptionElements);" \
      "  observer.observe(document.body, { childList: true, subtree: true });" \
      "  removeSubscriptionElements();" \
      "  setInterval(removeSubscriptionElements, 300);" \
      "  setTimeout(() => {observer.disconnect();}, 10000);" \
      "</script>" \
      "" >> "$MOBILE_TPL"
fi
EOF

# 2. Hacer ejecutable
chmod +x /usr/local/bin/pve-remove-nag.sh

# 3. Configurar para que se ejecute automÃ¡ticamente tras cada apt upgrade
cat > /etc/apt/apt.conf.d/no-nag-script << 'EOF'
DPkg::Post-Invoke { "/usr/local/bin/pve-remove-nag.sh"; };
EOF

# 4. Ejecutar ahora
/usr/local/bin/pve-remove-nag.sh

# 5. Reiniciar servicio web
systemctl restart pveproxy
```

### QuÃ© hace

| Componente | AcciÃ³n |
|------------|--------|
| **Web UI** | Modifica `proxmoxlib.js` para saltar la comprobaciÃ³n de suscripciÃ³n |
| **Mobile UI** | Inyecta JavaScript que elimina diÃ¡logos y cards de suscripciÃ³n |
| **Auto-ejecuciÃ³n** | Se ejecuta automÃ¡ticamente despuÃ©s de cada `apt upgrade` |

---

## ðŸ–¼ï¸ MÃ¡quinas Virtuales

### VM 200: Windows 11 Pro

| Propiedad | Valor |
|-----------|-------|
| **VMID** | 200 |
| **Nombre** | windows11 |
| **OS** | Windows 11 Pro 25H2 |
| **CPU** | 8 cores (host) |
| **RAM** | 16 GB |
| **Disco** | 64 GB (VirtIO SCSI, SSD) |
| **Red** | VirtIO, bridge vmbr0 |
| **BIOS** | UEFI (OVMF) |
| **TPM** | 2.0 |
| **Display** | VirtIO (sin GPU passthrough) |
| **MAC** | BC:24:11:95:54:95 |

#### Acceso remoto

- **RDP:** Habilitado (puerto 3389)
- **ConexiÃ³n:** `mstsc /v:[IP-Windows]` o Microsoft Remote Desktop en Mac

#### Recrear VM desde cero

```bash
# 1. Crear VM base
qm create 200 \
    --name windows11 \
    --memory 16384 \
    --cores 8 \
    --cpu host \
    --machine q35 \
    --bios ovmf \
    --net0 virtio,bridge=vmbr0 \
    --scsihw virtio-scsi-single \
    --scsi0 local-lvm:64,ssd=1,discard=on \
    --ostype win11 \
    --tpmstate0 local-lvm:1,version=v2.0 \
    --efidisk0 local-lvm:1 \
    --vga virtio

# 2. Conectar ISOs para instalaciÃ³n
qm set 200 --sata0 backup-storage:iso/es-es_windows_11.iso,media=cdrom
qm set 200 --sata1 backup-storage:iso/virtio-win.iso,media=cdrom
qm set 200 --boot order='sata0;scsi0'

# 3. Iniciar e instalar
qm start 200
# Durante instalaciÃ³n: cargar driver VirtIO desde D:\amd64\w11

# 4. Tras instalar, quitar ISOs
qm set 200 --delete sata0 --delete sata1
qm set 200 --boot order='scsi0'
```

#### Post-instalaciÃ³n

1. Instalar drivers VirtIO: `D:\virtio-win-guest-tools.exe`
2. Activar RDP: ConfiguraciÃ³n â†’ Sistema â†’ Escritorio remoto
3. Windows Update

---

# ðŸ“¦ CONTENEDOR LXC: alpine-vaultwarden (CT 101)

Gestor de contraseÃ±as compatible con Bitwarden, instalado via ProxMenux.

## ConfiguraciÃ³n

| Propiedad | Valor |
|-----------|-------|
| **VMID** | 101 |
| **OS** | Alpine Linux |
| **Hostname** | alpine-vaultwarden |
| **Cores** | 1 |
| **RAM** | 256 MB |
| **Swap** | 512 MB |
| **Disco** | 1 GB (local-lvm) |
| **Red** | DHCP via vmbr0 |
| **MAC** | BC:24:11:41:45:BE |
| **IP** | 192.168.50.148 |
| **Autostart** | SÃ­ |
| **Features** | nesting=1, keyctl=1 |
| **Unprivileged** | SÃ­ |

## Acceso

| Servicio | URL |
|----------|-----|
| **Vaultwarden Web** | `https://192.168.50.148:8000` |

## Certificado SSL (mkcert)

La app mÃ³vil de Bitwarden requiere HTTPS con un certificado vÃ¡lido. Para uso local/VPN, usamos **mkcert** para crear una CA (Autoridad Certificadora) local.

| Propiedad | Valor |
|-----------|-------|
| **Tipo** | Certificado local firmado por CA propia |
| **VÃ¡lido para** | `192.168.50.148`, `vaultwarden.local`, `localhost` |
| **Expira** | Marzo 2028 |
| **Certificado** | `/etc/ssl/certs/vaultwarden-selfsigned.crt` |
| **Clave** | `/etc/ssl/private/vaultwarden-selfsigned.key` |

### Pasos realizados para configurar HTTPS

#### 1. Instalar mkcert en Mac

```bash
brew install mkcert
```

#### 2. Crear CA local e instalar en el sistema

```bash
mkcert -install
# Pide contraseÃ±a sudo para aÃ±adir la CA al llavero del sistema
```

Esto crea la CA en `~/Library/Application Support/mkcert/rootCA.pem`.

#### 3. Generar certificado para Vaultwarden

```bash
mkcert -cert-file /tmp/vaultwarden.crt -key-file /tmp/vaultwarden.key \
  192.168.50.148 vaultwarden.local localhost
```

#### 4. Copiar certificados al servidor Proxmox

```bash
scp /tmp/vaultwarden.crt /tmp/vaultwarden.key root@192.168.50.8:/tmp/
```

#### 5. Instalar certificados en el LXC 101 y reiniciar

```bash
ssh root@192.168.50.8 "pct push 101 /tmp/vaultwarden.crt /etc/ssl/certs/vaultwarden-selfsigned.crt && \
  pct push 101 /tmp/vaultwarden.key /etc/ssl/private/vaultwarden-selfsigned.key && \
  pct exec 101 -- rc-service vaultwarden restart"
```

---

### Instalar CA en dispositivos mÃ³viles

Para que la app de Bitwarden confÃ­e en el certificado, hay que instalar la CA de mkcert en cada dispositivo.

**Obtener el archivo CA:**
```bash
# Ver ubicaciÃ³n
mkcert -CAROOT
# Copiar a ubicaciÃ³n accesible
cp "$(mkcert -CAROOT)/rootCA.pem" ~/Desktop/mkcert-CA.crt
```

#### iOS (iPhone/iPad)

1. **Enviar el archivo** `mkcert-CA.crt` al iPhone por AirDrop, email, o iCloud Drive
2. **Abrir el archivo** â†’ Aparece "Perfil descargado"
3. **Instalar perfil:**
   - Ir a **Ajustes â†’ General â†’ VPN y gestiÃ³n de dispositivos**
   - Tocar el perfil descargado â†’ **Instalar**
   - Introducir cÃ³digo de desbloqueo si lo pide
4. **Activar confianza completa:**
   - Ir a **Ajustes â†’ General â†’ InformaciÃ³n â†’ Ajustes de certificados**
   - En "Activar confianza total para certificados raÃ­z", activar el certificado de mkcert
5. **Configurar app Bitwarden:**
   - Abrir Bitwarden â†’ Tocar engranaje (âš™ï¸) antes de login
   - Seleccionar **Self-hosted**
   - URL: `https://192.168.50.148:8000`
   - Guardar y crear cuenta/login

#### Android

1. **Copiar el archivo** `mkcert-CA.crt` al dispositivo (cable USB, email, Drive, etc.)
2. **Instalar certificado:**
   - Ir a **Ajustes â†’ Seguridad â†’ MÃ¡s ajustes de seguridad**
   - Tocar **Instalar desde almacenamiento del dispositivo**
   - Seleccionar el archivo `mkcert-CA.crt`
   - Dar un nombre (ej: "mkcert local")
   - Seleccionar "VPN y apps" como uso
3. **Configurar app Bitwarden:**
   - Abrir Bitwarden â†’ Tocar engranaje (âš™ï¸) antes de login
   - Seleccionar **Self-hosted**
   - URL: `https://192.168.50.148:8000`
   - Guardar y crear cuenta/login

> **Nota:** En algunos Android, la ruta puede variar. Buscar "Instalar certificado" en Ajustes.

---

### Regenerar certificado (si expira o cambia la IP)

```bash
# En Mac (requiere mkcert instalado)
mkcert -cert-file /tmp/vaultwarden.crt -key-file /tmp/vaultwarden.key \
  192.168.50.148 vaultwarden.local localhost

# Copiar al servidor y reiniciar
scp /tmp/vaultwarden.* root@192.168.50.8:/tmp/
ssh root@192.168.50.8 "pct push 101 /tmp/vaultwarden.crt /etc/ssl/certs/vaultwarden-selfsigned.crt && \
  pct push 101 /tmp/vaultwarden.key /etc/ssl/private/vaultwarden-selfsigned.key && \
  pct exec 101 -- rc-service vaultwarden restart"
```

## Prompt personalizado (Alpine sh)

Archivo: `/root/.profile`

```bash
export PS1="\033[1;32m\u\033[0m@\033[1;35mvaultwarden\033[0m:\033[1;34m\w\033[0m\$ "
```

Resultado: `root`(verde)`@vaultwarden`(magenta)`:/ruta`(azul)`$`

## InstalaciÃ³n (via ProxMenux)

Instalado automÃ¡ticamente con:
```bash
menu â†’ LXC â†’ Vaultwarden
```

---

# ðŸ“¦ CONTENEDOR LXC: docker-commander (CT 100)

Todo en esta secciÃ³n estÃ¡ configurado en el contenedor LXC o es su definiciÃ³n desde Proxmox.

---

## CreaciÃ³n del contenedor

### Paso 1: Descargar template Debian 13 (Trixie)

```bash
# Actualizar lista de templates
pveam update

# Buscar Ãºltima versiÃ³n de Debian 13
pveam available | grep "debian-13-standard"
# Ejemplo de salida: debian-13-standard_13.1-2_amd64.tar.zst

# Descargar la versiÃ³n que aparezca en backup-storage (persiste tras reinstalar)
pveam download backup-storage debian-13-standard_13.1-2_amd64.tar.zst
```

### Paso 2: Crear el contenedor

```bash
# Crear contenedor con configuraciÃ³n bÃ¡sica
# IMPORTANTE: La MAC estÃ¡ fija para que el router asigne siempre la misma IP
# Usar el template descargado (ajustar versiÃ³n si es diferente)
pct create 100 backup-storage:vztmpl/debian-13-standard_13.1-2_amd64.tar.zst \
    --hostname docker-commander \
    --storage local-lvm \
    --rootfs local-lvm:32 \
    --memory 12288 \
    --swap 2048 \
    --cores 4 \
    --net0 name=eth0,bridge=vmbr0,hwaddr=BC:24:11:AF:E8:2E,ip=dhcp \
    --features nesting=1,keyctl=1 \
    --onboot 1 \
    --unprivileged 1
```

> **Nota:** MAC `BC:24:11:AF:E8:2E` â†’ IP asignada por router: `192.168.50.67`

### Paso 3: AÃ±adir configuraciÃ³n avanzada (GPU + CPU Pinning)

```bash
# Editar configuraciÃ³n del contenedor
cat >> /etc/pve/lxc/100.conf << 'EOF'

# --- OPTIMIZACION HARDWARE (Zen 5c Pinning) ---
# Tu CPU tiene 24 hilos (0 a 23).
# 0-7: P-Cores (Alto rendimiento - Reservados para el Host/VMs Gaming).
# 8-23: E-Cores (Eficiencia - Asignados a este contenedor).
lxc.cgroup2.cpuset.cpus: 8-23

# --- GPU & NPU PASSTHROUGH (AMD Strix Point) ---
# Mapeo verificado para Kernel 6.17 (25-Dic-2025)
lxc.cgroup2.devices.allow: c 226:0 rwm
lxc.cgroup2.devices.allow: c 226:128 rwm
lxc.cgroup2.devices.allow: c 234:0 rwm
lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file
lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file
lxc.mount.entry: /dev/kfd dev/kfd none bind,optional,create=file
EOF
```

### Paso 4: Iniciar y configurar Docker dentro del contenedor

```bash
# Iniciar contenedor
pct start 100

# Entrar al contenedor
pct enter 100

# Dentro del contenedor: instalar Docker
apt update && apt upgrade -y
apt install -y curl gnupg lsb-release ca-certificates

# AÃ±adir repo Docker
curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable" > /etc/apt/sources.list.d/docker.list

# Instalar Docker
apt update
apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Verificar
docker --version
docker compose version

# Salir del contenedor
exit
```

---

## ConfiguraciÃ³n final del contenedor

**Archivo:** `/etc/pve/lxc/100.conf`

| Propiedad | Valor |
|-----------|-------|
| **VMID** | 100 |
| **OS** | Debian 12 |
| **Hostname** | docker-commander |
| **Cores** | 4 (pinned a E-Cores 8-23) |
| **RAM** | 12 GB |
| **Swap** | 2 GB |
| **Disco** | 32 GB (local-lvm) |
| **Red** | DHCP via vmbr0 |
| **Autostart** | SÃ­ |
| **Features** | nesting=1, keyctl=1 |

---

## Prompt personalizado (Bash)

Archivo: `/root/.bashrc`

```bash
# Prompt con colores
export PS1="\[\033[1;32m\]\u\[\033[0m\]@\[\033[1;36m\]docker-commander\[\033[0m\]:\[\033[1;34m\]\w\[\033[0m\]\$ "

# Alias Ãºtiles
alias ll="ls -la --color=auto"
alias dc="docker compose"
alias dps="docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'"
```

Resultado: `root`(verde)`@docker-commander`(cyan)`:/ruta`(azul)`$`

## ðŸ’¾ Backup y RestauraciÃ³n

### Backup existente

```
/mnt/backups/dump/vzdump-lxc-100-2025_12_25-21_24_47.tar.zst
```

### Crear backup manual

```bash
# Backup con snapshot (sin downtime)
vzdump 100 --storage backup-storage --mode snapshot --compress zstd

# Backup deteniendo el contenedor (mÃ¡s consistente)
vzdump 100 --storage backup-storage --mode stop --compress zstd
```

### Restaurar backup

#### OpciÃ³n A: Interfaz web
1. **Datacenter** â†’ **Storage** â†’ `backup-storage`
2. PestaÃ±a **Content** â†’ Seleccionar backup
3. Clic derecho â†’ **Restore**
4. Elegir VMID y storage destino

#### OpciÃ³n B: LÃ­nea de comandos

```bash
# Ver backups disponibles
ls -la /mnt/backups/dump/

# Restaurar sobreescribiendo el contenedor actual
pct stop 100
pct restore 100 /mnt/backups/dump/vzdump-lxc-100-2025_12_25-21_24_47.tar.zst \
    --storage local-lvm
pct start 100

# O restaurar como nuevo contenedor
pct restore 101 /mnt/backups/dump/vzdump-lxc-100-2025_12_25-21_24_47.tar.zst \
    --storage local-lvm \
    --hostname docker-commander-restored
```

#### Opciones de restauraciÃ³n

| OpciÃ³n | Uso |
|--------|-----|
| `--storage local-lvm` | Donde guardar el disco |
| `--hostname nuevo-nombre` | Cambiar hostname |
| `--force` | Sobreescribir si existe |
| `--unprivileged` | Mantener como unprivileged |

> **Nota:** Tras restaurar, verificar que la configuraciÃ³n de GPU passthrough y CPU pinning sigue correcta en `/etc/pve/lxc/100.conf`

---

## GPU/NPU Passthrough (AMD Strix Point)

| Dispositivo | Major:Minor | DescripciÃ³n |
|-------------|-------------|-------------|
| `/dev/dri/card0` | 226:0 | GPU AMD Radeon 890M |
| `/dev/dri/renderD128` | 226:128 | Render node (aceleraciÃ³n) |
| `/dev/kfd` | 234:0 | ROCm/OpenCL |

### Verificar GPU dentro del contenedor

```bash
pct enter 100
ls -la /dev/dri/
# DeberÃ­a mostrar: card0, renderD128
```

---

## ðŸ³ Stacks de Portainer

Los servicios Docker se gestionan desde **Portainer** (http://[IP-contenedor]:9000) usando Stacks.

### Paso 1: Instalar Portainer primero (Ãºnico servicio con docker run)

```bash
pct enter 100

docker volume create portainer_data

docker run -d \
  --name portainer \
  --restart unless-stopped \
  -p 9000:9000 \
  -p 9443:9443 \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v portainer_data:/data \
  portainer/portainer-ce:latest
```

### Paso 2: Crear stacks desde Portainer

Desde la web de Portainer â†’ **Stacks** â†’ **Add stack** â†’ pegar el YAML.

---

### Stack: home-assistant

**Directorios a crear:**
```bash
mkdir -p /opt/homeassistant/config
```

```yaml
version: '3'

services:
  homeassistant:
    container_name: homeassistant
    image: "homeassistant/home-assistant:stable"
    volumes:
      - /opt/homeassistant/config:/config
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    restart: unless-stopped
    network_mode: host
```

---

### Stack: adguard

**Directorios a crear:**
```bash
mkdir -p /opt/adguard/work /opt/adguard/conf
```

```yaml
version: "3.8"

services:
  adguard:
    image: adguard/adguardhome:latest
    container_name: adguard
    restart: unless-stopped
    network_mode: host
    volumes:
      - /opt/adguard/work:/opt/adguardhome/work
      - /opt/adguard/conf:/opt/adguardhome/conf
```

### Script: Prewarm DNS (precalentar cachÃ©)

Mantiene los dominios mÃ¡s usados siempre en cachÃ©, refrescÃ¡ndolos cada 20 minutos.

**Lista de dominios:** `/root/scripts/domains.txt`

```
# CDNs
cdn.jsdelivr.net
cdnjs.cloudflare.com
fonts.googleapis.com
fonts.gstatic.com

# YouTube / Twitch
www.youtube.com
i.ytimg.com
www.twitch.tv
static.twitchcdn.net

# Google / GitHub
www.google.com
www.googleapis.com
github.com
raw.githubusercontent.com
```

**Script:** `/root/scripts/prewarm-dns.sh`

```bash
#!/bin/bash
DOMAINS_FILE="/root/scripts/domains.txt"
LOG="/var/log/prewarm-dns.log"

echo "$(date '+%H:%M:%S') Prewarm iniciado" >> "$LOG"
COUNT=0
while IFS= read -r domain; do
    [[ -z "$domain" || "$domain" == \#* ]] && continue
    dig +short +time=2 "$domain" @127.0.0.1 >/dev/null 2>&1 && ((COUNT++))
done < "$DOMAINS_FILE"
echo "$(date '+%H:%M:%S') $COUNT dominios refrescados" >> "$LOG"
```

**Cron (cada 20 min):** `*/20 * * * * /root/scripts/prewarm-dns.sh`

---

### Stack: indexers (Jackett + FlareSolverr)

**Directorios a crear:**
```bash
mkdir -p /root/docker/jackett/config /root/docker/jackett/downloads
```

```yaml
services:
  jackett:
    image: lscr.io/linuxserver/jackett:latest
    container_name: jackett
    environment:
      - PUID=0
      - PGID=0
      - TZ=Europe/Madrid
      - AUTO_UPDATE=true
    volumes:
      - /root/docker/jackett/config:/config
      - /root/docker/jackett/downloads:/downloads
    ports:
      - 9117:9117
    restart: unless-stopped

  flaresolverr:
    image: flaresolverr/flaresolverr:latest
    container_name: flaresolverr
    environment:
      - LOG_LEVEL=info
      - LOG_HTML=false
      - CAPTCHA_SOLVER=none
      - TZ=Europe/Madrid
    ports:
      - "8191:8191"
    restart: unless-stopped
```

---

### Stack: uptime-kuma

**Directorios a crear:**
```bash
mkdir -p /opt/uptime-kuma
```

```yaml
services:
  uptime-kuma:
    image: louislam/uptime-kuma:2
    container_name: uptime-kuma
    dns:
      - 192.168.50.67   # AdGuard (primario)
      - 8.8.8.8         # Google (fallback)
      - 1.1.1.1         # Cloudflare (fallback)
    ports:
      - 3001:3001
    volumes:
      - /opt/uptime-kuma:/app/data
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped
```

**FunciÃ³n:** MonitorizaciÃ³n de disponibilidad de servicios (up/down, latencia, notificaciones).

---

### Resumen de servicios

| Nombre | Stack | Puerto | FunciÃ³n |
|--------|-------|--------|---------|
| **portainer** | (docker run) | 9000 | GestiÃ³n Docker |
| **homeassistant** | home-assistant | 8123 | DomÃ³tica |
| **adguard** | adguard | 3000/53 | DNS + Bloqueador ads |
| **jackett** | indexers | 9117 | Indexador torrents |
| **flaresolverr** | indexers | 8191 | Bypass Cloudflare |
| **uptime-kuma** | uptime-kuma | 3001 | MonitorizaciÃ³n |

---

# ðŸŒ Accesos Web

| Servicio | UbicaciÃ³n | URL |
|----------|-----------|-----|
| **Proxmox** | Nodo | https://192.168.50.8:8006 |
| **Vaultwarden** | LXC 101 | https://192.168.50.148:8000 |
| **Portainer** | LXC 100 | http://192.168.50.67:9000 |
| **Uptime Kuma** | LXC 100 | http://192.168.50.67:3001 |
| **Home Assistant** | LXC 100 | http://192.168.50.67:8123 |
| **AdGuard** | LXC 100 | http://192.168.50.67:3000 |
| **Jackett** | LXC 100 | http://192.168.50.67:9117 |
| **FlareSolverr** | LXC 100 | http://192.168.50.67:8191 |

> **Nota:** La IP de LXC 100 (`192.168.50.67`) estÃ¡ ligada a la MAC `BC:24:11:AF:E8:2E` en el router.

---

# ðŸš€ PrÃ³ximas mejoras

Para ver las mejoras planificadas y cosas por hacer, consulta:

ðŸ“„ **[TODO.md](./TODO.md)**
